{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trca_matrix(X):\n",
    "    \n",
    "    n_chans = X.shape[1]\n",
    "    n_trial = X.shape[0]\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "\n",
    "    # Computation of correlation matrices\n",
    "    for trial_i in range(n_trial):\n",
    "        for trial_j in range(n_trial):\n",
    "            x_i = X[trial_i, :, :]\n",
    "            x_j = X[trial_j, :, :]\n",
    "            S = S + np.dot(x_i, x_j.T)\n",
    "    X = np.transpose(X, (1, 2, 0))\n",
    "    X1 = X.reshape((n_chans, -1),order='F')\n",
    "    X1 = X1 - np.mean(X1, axis=1, keepdims=True)\n",
    "    Q = np.dot(X1, X1.T)\n",
    "    S = np.matrix(S)\n",
    "    Q = np.matrix(Q)\n",
    "    # TRCA eigenvalue algorithm\n",
    "    [W, V] = np.linalg.eig(np.dot(Q.I,S))\n",
    "\n",
    "    return V[:, 0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(split_type='K_Fold',test_sample_num = None, total_sample_num = None):\n",
    "    if split_type == \"K_Fold\":\n",
    "        if total_sample_num%test_sample_num != 0:\n",
    "            raise Exception('The sample cannot be divided into test subsets')\n",
    "        else:\n",
    "            folders_num = int(total_sample_num/test_sample_num)\n",
    "            split_index = np.zeros((folders_num,total_sample_num))\n",
    "            for folder_index in range(folders_num):\n",
    "                split_index[folder_index, folder_index*test_sample_num:(folder_index+1)*test_sample_num] = np.ones((test_sample_num,))\n",
    "        return split_index\n",
    "    \n",
    "    raise Exception('split_type was not defined, use \\'K_Fold \\' or define it manually')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      "  1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Test function for train_test_split()\n",
    "split_index = train_test_split(test_sample_num=5,total_sample_num=30)\n",
    "print(split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_match(testsample,spatial_filters,template_storage):\n",
    "    if len(testsample.shape) != 2:\n",
    "        raise TypeError('testsample should be a two dimensional vector')\n",
    "    corrcoef_storage = list()\n",
    "    spatial_filter = np.squeeze(np.array(list(spatial_filters.values())))\n",
    "    for template_iter in template_storage.keys():\n",
    "        corrcoef_storage.append(np.corrcoef(np.dot(spatial_filter,testsample),np.dot(spatial_filter,template_storage[template_iter]))[0,1])\n",
    "    \n",
    "    corrcoef_storage = np.array(corrcoef_storage)\n",
    "\n",
    "    return corrcoef_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_counter(coef_vector,label,counter,right_counter):\n",
    "    if np.argmax(coef_vector) == int(label):\n",
    "        counter += 1\n",
    "        right_counter += 1\n",
    "    else:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class filter_applyer():\n",
    "    def __init__(self,sample_rate,filter_type,high_cut_frequency,low_cut_frequency,filter_order) -> None:\n",
    "        self.sample_rate = sample_rate\n",
    "        self.filter_type = filter_type\n",
    "        self.high_cut_frequency = high_cut_frequency\n",
    "        self.low_cut_frequency = low_cut_frequency\n",
    "        self.filter_order = filter_order\n",
    "        self._filter_design()\n",
    "    \n",
    "    def _filter_design(self):\n",
    "        if self.filter_type == 'FIR':\n",
    "            if self.filter_order%2 != 0:\n",
    "                self.filter_order+=1\n",
    "            # Nyquist rate of signal\n",
    "            nyq_rate = self.sample_rate/2.0\n",
    "            # 1-D array cut of\n",
    "            freq_cutoff = [self.high_cut_frequency/nyq_rate, self.low_cut_frequency/nyq_rate]\n",
    "            # Get the fir filter coef\n",
    "            taps = scipy.signal.firwin(self.filter_order, freq_cutoff, window='hamming', pass_zero='bandpass')\n",
    "            self.filter_b = taps\n",
    "            self.filter_a = 1\n",
    "        elif self.filter_type == 'IIR':\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    def filter_apply(self,data):\n",
    "        filter_data = scipy.signal.lfilter(self.filter_b,self.filter_a,data)\n",
    "        return filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "[-4.71842418e-04  1.26631211e-03  5.85815119e-04 -1.66662178e-03\n",
      "  1.04112726e-03  6.11615084e-04 -5.35670174e-03 -8.66699792e-04\n",
      "  1.14171297e-04 -1.32803884e-02 -6.99903835e-03 -9.47797484e-04\n",
      " -2.59797972e-02 -1.94487854e-02 -9.84152473e-04 -4.20330734e-02\n",
      " -3.98547428e-02  4.76130221e-03 -5.81367401e-02 -7.32096984e-02\n",
      "  3.09527471e-02 -7.01321623e-02 -1.67038331e-01  2.38958350e-01\n",
      "  5.91273788e-01  2.38958350e-01 -1.67038331e-01 -7.01321623e-02\n",
      "  3.09527471e-02 -7.32096984e-02 -5.81367401e-02  4.76130221e-03\n",
      " -3.98547428e-02 -4.20330734e-02 -9.84152473e-04 -1.94487854e-02\n",
      " -2.59797972e-02 -9.47797484e-04 -6.99903835e-03 -1.32803884e-02\n",
      "  1.14171297e-04 -8.66699792e-04 -5.35670174e-03  6.11615084e-04\n",
      "  1.04112726e-03 -1.66662178e-03  5.85815119e-04  1.26631211e-03\n",
      " -4.71842418e-04]\n"
     ]
    }
   ],
   "source": [
    "# Test filter\n",
    "filter = filter_applyer(250,'FIR',6,80,48)\n",
    "print(filter.sample_rate)\n",
    "print(filter.filter_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_trainer():\n",
    "    \n",
    "    def __init__(self, usrname, data_path, block_num, spatial_filter_type='TRCA', cross_validation=True) -> None:\n",
    "        with open('config.json') as file:\n",
    "            self.data_config = json.load(file)\n",
    "        data_dir = pjoin(data_path,usrname,block_num,'EEG.mat')\n",
    "        self.raw_data = loadmat(data_dir)\n",
    "        self.raw_data = self.raw_data['EEG'][0]\n",
    "        self.event = self.raw_data['event'][0]\n",
    "        self.event_size = self.event.shape[0]\n",
    "        self.data = self.raw_data['data'][0]\n",
    "        # Read experiment paramter setting in json file\n",
    "        self.blocks_in_data = self.data_config['blocks_in_data']\n",
    "        self.epochs_in_data = self.data_config['epochs_in_trials']\n",
    "        self.slice_data_storage = dict()\n",
    "        self.template_storage = dict()\n",
    "        self.sample_rate = self.raw_data['srate'][0][0][0]\n",
    "        self.epoch_length = int(self.data_config['epoch_length'][block_num]*self.sample_rate)\n",
    "        self.visual_delay = int(0.14*self.sample_rate)\n",
    "        self.cross_validation = cross_validation\n",
    "        # Initail time filter paramters here\n",
    "        self.filter_object = filter_applyer(self.sample_rate,'FIR',7.0,80.0,64)\n",
    "        self.spatial_filter_type = spatial_filter_type\n",
    "        self.template_storage = dict()\n",
    "\n",
    "        self.data_slice()\n",
    "   \n",
    "    def data_slice(self):\n",
    "        for event_iter in range(self.event_size):\n",
    "            event_type = self.event[event_iter][0][0][0]\n",
    "            event_time_stamp = int(self.event[event_iter][0][1][0][0])\n",
    "            epoch_cut = self.data[:,event_time_stamp+self.visual_delay:event_time_stamp+self.visual_delay+self.epoch_length]\n",
    "            #Zero-mean\n",
    "            epoch_cut = epoch_cut-np.mean(epoch_cut,axis=-1,keepdims=True)\n",
    "            filtered_epoch_cut = self.filter_object.filter_apply(epoch_cut)\n",
    "            #fig,ax = plt.subplots()\n",
    "            #plt.plot(filtered_epoch_cut[1,:])\n",
    "            event_list = self.slice_data_storage.setdefault(event_type, list())\n",
    "            event_list.append(filtered_epoch_cut)\n",
    "        self.event_series = self.slice_data_storage.keys()\n",
    "        print(self.slice_data_storage['1'][0].shape)\n",
    "        print('Data sliced ready!')\n",
    "        print('Total number of events: {}'.format(len(self.slice_data_storage)))\n",
    "    \n",
    "    def trainer(self):\n",
    "        self.spatial_filters = dict()\n",
    "        for train_trial_iter in self.event_series:\n",
    "            self.spatial_filters[train_trial_iter] = self.feature_extract(self.slice_data_storage[train_trial_iter])\n",
    "            self.template_calculate(self.slice_data_storage[train_trial_iter], train_trial_iter)\n",
    "\n",
    "    def feature_extract(self,data):\n",
    "        if self.spatial_filter_type == 'TRCA':\n",
    "            return trca_matrix(data)\n",
    "        raise Exception('Method not define, you can define it manually!')\n",
    "    \n",
    "    def template_calculate(self, train_data, event_type):\n",
    "        self.template_storage[event_type] = np.mean(train_data, axis=0)\n",
    "    \n",
    "    def train_result_get(self):\n",
    "        return self.spatial_filters, self.template_storage    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_cross_validation(data_trainer):\n",
    "    \n",
    "    def cross_validation_runner(self):\n",
    "        self.dataset_split_index = train_test_split(split_type='K_Fold',test_sample_num=self.epochs_in_data, total_sample_num=self.epochs_in_data*self.blocks_in_data)\n",
    "        for cross_validation_iter in range(self.dataset_split_index.shape[0]):\n",
    "            print('cross validation loop: {}'.format(cross_validation_iter))\n",
    "            validation_index = self.dataset_split_index[cross_validation_iter,:]\n",
    "            self.trainer(1-validation_index)\n",
    "            self.tester(validation_index)\n",
    "    \n",
    "    def trainer(self,select_index):\n",
    "        self.spatial_filters = dict()\n",
    "        for train_trial_iter in self.event_series:\n",
    "            self.spatial_filters[train_trial_iter] = self.feature_extract(np.array(self.slice_data_storage[train_trial_iter])[select_index==1,:,:])\n",
    "            self.template_calculate(np.array(self.slice_data_storage[train_trial_iter])[select_index==1,:,:],train_trial_iter)\n",
    "    \n",
    "    def tester(self,select_index):\n",
    "        self.corrcoef_storage = dict()\n",
    "        self.result_counter = 0\n",
    "        self.result_right_counter = 0\n",
    "        for test_trial_iter in self.event_series:\n",
    "            test_epoches = np.array(self.slice_data_storage[test_trial_iter])[select_index==1,:,:]\n",
    "            corrcoef_list = self.corrcoef_storage.setdefault(test_trial_iter, list())\n",
    "            for test_epoch_iter in range(test_epoches.shape[0]):\n",
    "                coef_vector = pattern_match(test_epoches[test_epoch_iter,:,:],self.spatial_filters,self.template_storage)\n",
    "                corrcoef_list.append(coef_vector)\n",
    "                result_counter(coef_vector,test_trial_iter,self.result_counter,self.result_right_counter)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100)\n",
      "Data sliced ready!\n",
      "Total number of events: 12\n",
      "cross validation loop: 0\n",
      "cross validation loop: 1\n",
      "cross validation loop: 2\n",
      "cross validation loop: 3\n",
      "cross validation loop: 4\n",
      "cross validation loop: 5\n"
     ]
    }
   ],
   "source": [
    "# Test cross_validation class\n",
    "tester = data_cross_validation('mengqiangfan','./ThesisData/','block2')\n",
    "tester.cross_validation_runner()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbad2d039937c9fe990f69a077a800efd89bdf2e37926a364738b268742dce4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('EEGtools': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
